{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "answering-atlanta",
   "metadata": {},
   "source": [
    "# Findings, Evaluation, Discussion & Outlook:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thousand-chrome",
   "metadata": {},
   "source": [
    "\n",
    "First of all, after importing the data, I did a Data Assessment. I drew a line graph to see what the data looked like.  Not only did I find a drop in the data that could easily be explained by a technicial change made on our platform, but saw a decreasing trend in the data. Furthermore, I checked for missing values, outliers, it's distribution and any other anomaly. By looking at the data, no missing values nor outliers that couldn't be explained, were found. I discovered a decreasing trend in Visits and a weekday seasonality (on a weekly basis) which could be found using some Feature Engineering like working with the date times. \n",
    "\n",
    "Based on the data analysis, I figured out that the best fit for a classical Maschine Learning model would be a SARIMA(X) model due to it's possibility to take seasonality into consideration. After plotting the ACF and PCF, I came up with the combination of hyper parameter (p, d, q) x (P, D, Q )S => (0, 1, 1) x (0, 1, 1)7. By looking at the performance measures, I came across the issue that the values for the Mean Square Error was very high. Usually a good indicator didn't help here. This is probably due to the high volatility in the daily Visits related to the News situation. Therefore, I decided to go for R2 as a performance measure. With the first combination, I reached an R-squared of 0.87, which isnt too bad. Nonetheless, I wanted to improve the score and did a grid search for the hyper parameter optimazation using the AIC criteria. The resulting (p, d, q) x (P, D, Q )S => (1, 0, 1) x (1, 1, 1)7 led to an R-squared of 0.86, which is a good result but slightly below the first combination. Still the forecast looks far more better on the grid search combination.\n",
    "\n",
    "For the Deep Learning Model, I decided to use an LSTM (Long Short Term Memory). Due to it's capability to take past events into consideration and only store the relevant information over time, it seemed a good fit. I splitted the data 80:20 for train and test and used an adam optimizer. I tried to figure out the best hyper parameter combination comprising of batch size, number of neurons and epochs. After a couple of iterations, I came to the conclusion that a \n",
    "batch_size = 45; lstm_neuron_number = 150 and epochs = 90 with an R-squared of 0.86 seems to be the best result. \n",
    "\n",
    "I tested both models using different hyper parameter combinations to better evaluated the results using R-squared as a performance indicator. With a slightly better result of R-squared = 0.87, the SARMIA(X) model outperformed the LSTM model to predict future values for the daily Visits.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southwest-visitor",
   "metadata": {},
   "source": [
    "### Evaluation / Discussion / Outlook\n",
    "There is always room for optimising the perfomance or using different approaches to get better results. In this section, I will mention a couple of things that could be optimized or done different to perform better.\n",
    "\n",
    "When looking for optimisation in the SARIMA parameter combination, one could try out to use the BIC (Bayesian information criterion) instead of AIC to see whether another combination might lead to better results in MSE and R2. \n",
    "\n",
    "Furthermore, using a differenced times series as an input for the model could positively contribute to the model's performance even if we have chosen d=1 for differencing. But since the models in general work better with stationary data, this could be one aspect of further improvement. \n",
    "\n",
    "Moreover, one could argue that R2 is not the best indicator when it comes to fully evaluate the model's prediction. One reason is that we are interested in the accuracy of the monthly prediction of our model. If one only considers the total R2, one looses the information about the performance for further away future values vs predictions that lay in the near future. So, you could have several month of good performance, but the predictions further way are pretty poor and you would still end up believing that the model's performance in general is good. In order to avoid this bias, one could calculate the R2 on a monthly basis and check it's values. Another reason to hold against the R2 performance measurement is that it does not tell how well it predicted future values, but only how well it fits on past events. Maybe, the use of the standard error, standard deviation, confidence intervall or prediction interval in combination with R-squared could be of help. A higher R-square is likely to have a smaller confidence interval or smaller prediction interval and lower standard error.\n",
    "\n",
    "The implemented LSTM has only one layer but can have multiple layers stacked over one another. This could contribute to a better performance of the model. Furthermore, if the return_sequence is set to \"true\", one could then use the output sequence to be used as input for the next layer. Moreover, the hyper parameter configuration could be further tested to optimize the result.\n",
    "\n",
    "Since we are not particularly interested in the daily visit forecast, but rather in the monthly prediction, one could aggregate the daily visits to monthly visits and try to predict the future value on a monthly basis and see how good the performance of the model will be.\n",
    "\n",
    "Another question that comes up is: Is there another model more suitable to predict future values for the data given? One obvious candidate for the dataset might be a multivariate times series prediction. Since we have a couple of News Sites in our dataset, and even have data of the competitors, publicly available, it is worth having a look into the correlation between the News Sites and take those into consideration as well. One possible model to model all this (different News Sites from our company as well as the competitors as an exogenous variable) could be done by a Vector Auto Regression model (VAR) that needs to be tested and evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comprehensive-cover",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
